{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install --quiet transformers \n!pip install --quiet pytorch-lightning ","metadata":{"execution":{"iopub.status.busy":"2022-05-16T05:19:53.240317Z","iopub.execute_input":"2022-05-16T05:19:53.240592Z","iopub.status.idle":"2022-05-16T05:20:14.339576Z","shell.execute_reply.started":"2022-05-16T05:19:53.240505Z","shell.execute_reply":"2022-05-16T05:20:14.338724Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns \nfrom transformers import AdamW, T5ForConditionalGeneration, T5TokenizerFast as T5Tokenizer\nimport pytorch_lightning as pl\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom pytorch_lightning.callbacks import ModelCheckpoint\nfrom pytorch_lightning.loggers import TensorBoardLogger\nimport textwrap\nfrom pathlib import Path\n\nimport seaborn as sns\nfrom tqdm.auto import tqdm\nfrom pylab import rcParams\nimport matplotlib.pyplot as plt \nfrom matplotlib import rc \nimport pandas as pd\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2022-05-16T05:20:14.343584Z","iopub.execute_input":"2022-05-16T05:20:14.343814Z","iopub.status.idle":"2022-05-16T05:20:22.595121Z","shell.execute_reply.started":"2022-05-16T05:20:14.343775Z","shell.execute_reply":"2022-05-16T05:20:22.594219Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"execution":{"iopub.status.busy":"2022-05-16T05:20:22.597056Z","iopub.execute_input":"2022-05-16T05:20:22.597328Z","iopub.status.idle":"2022-05-16T05:20:22.614209Z","shell.execute_reply.started":"2022-05-16T05:20:22.597289Z","shell.execute_reply":"2022-05-16T05:20:22.613467Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"pl.seed_everything(42)","metadata":{"execution":{"iopub.status.busy":"2022-05-16T05:20:22.617324Z","iopub.execute_input":"2022-05-16T05:20:22.617552Z","iopub.status.idle":"2022-05-16T05:20:22.630524Z","shell.execute_reply.started":"2022-05-16T05:20:22.617526Z","shell.execute_reply":"2022-05-16T05:20:22.629723Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/news-summary/news_summary.csv',encoding='latin-1')\ndf = df[['text','ctext']]\ndf.columns=[\"summary\", \"text\"]\ndf=df.dropna()\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-16T05:20:22.631966Z","iopub.execute_input":"2022-05-16T05:20:22.632399Z","iopub.status.idle":"2022-05-16T05:20:22.987482Z","shell.execute_reply.started":"2022-05-16T05:20:22.632361Z","shell.execute_reply":"2022-05-16T05:20:22.986741Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"train_df, test_df = train_test_split(df, test_size=0.1)\ntrain_df.shape, test_df.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-16T05:20:22.988830Z","iopub.execute_input":"2022-05-16T05:20:22.989091Z","iopub.status.idle":"2022-05-16T05:20:22.998732Z","shell.execute_reply.started":"2022-05-16T05:20:22.989055Z","shell.execute_reply":"2022-05-16T05:20:22.997838Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"class NewsSummaryDataset(Dataset):\n    def __init__(\n        self,\n        data: pd.DataFrame,\n        tokenizer: T5Tokenizer,\n        text_max_token_len: int = 512,\n        summary_max_token_len: int = 128):\n        \n        self.tokenizer = tokenizer\n        self.data = data\n        self.text_max_token_len = text_max_token_len\n        self.summary_max_token_len = summary_max_token_len\n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, index:int):\n        data_row = self.data.iloc[index]\n        text = data_row[\"text\"]\n        \n        text_encoding = tokenizer(data_row[\"text\"],max_length=self.text_max_token_len,\n                                 padding=\"max_length\", \n                                 truncation=True,\n                                 return_attention_mask=True,\n                                 add_special_tokens=True,\n                                 return_tensors=\"pt\")\n        \n        summary = data_row[\"summary\"]\n        summary_encoding = tokenizer(summary,max_length=self.summary_max_token_len,\n                                 padding=\"max_length\", \n                                 truncation=True,\n                                 return_attention_mask=True,\n                                 add_special_tokens=True,\n                                 return_tensors=\"pt\")\n        \n        labels= summary_encoding[\"input_ids\"] \n        labels[labels == 0] = -100\n        \n        return dict(\n            text=text, \n            summary=summary,\n            text_input_ids=text_encoding[\"input_ids\"].flatten(),\n            text_attention_mask=text_encoding[\"attention_mask\"].flatten(),\n            labels=labels.flatten(),\n            labels_attention_mask=summary_encoding[\"attention_mask\"].flatten())\n            ","metadata":{"execution":{"iopub.status.busy":"2022-05-16T05:20:23.000416Z","iopub.execute_input":"2022-05-16T05:20:23.000691Z","iopub.status.idle":"2022-05-16T05:20:23.011371Z","shell.execute_reply.started":"2022-05-16T05:20:23.000654Z","shell.execute_reply":"2022-05-16T05:20:23.010600Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"class NewsSummaryDataModule(pl.LightningDataModule):\n    def __init__(self, \n                train_df:pd.DataFrame,\n                test_df:pd.DataFrame,\n                tokenizer:T5Tokenizer,\n                batch_size: int = 8,\n                text_max_token_len: int = 512,\n                summary_max_token_len: int = 128):\n        super().__init__()\n        self.train_df=train_df\n        self.test_df=test_df\n        \n        self.batch_size=batch_size\n        self.tokenizer=tokenizer\n        self.text_max_token_len=text_max_token_len\n        self.summary_max_token_len= summary_max_token_len\n    \n    def setup(self, stage=None):\n        self.train_dataset =  NewsSummaryDataset(\n            self.train_df,\n            self.tokenizer,\n            self.text_max_token_len,\n            self.summary_max_token_len\n        )\n        self.test_dataset =  NewsSummaryDataset(\n            self.test_df,\n            self.tokenizer,\n            self.text_max_token_len,\n            self.summary_max_token_len\n        )\n    \n    def train_dataloader(self):\n        return DataLoader(\n            self.train_dataset,\n            batch_size=self.batch_size,\n            shuffle=True,\n            num_workers=2)\n    \n    def val_dataloader(self):\n        return DataLoader(\n            self.test_dataset,\n            batch_size=self.batch_size,\n            shuffle=False,\n            num_workers=2)\n    \n    def test_dataloader(self):\n        return DataLoader(\n            self.test_dataset,\n            batch_size=self.batch_size,\n            shuffle=False,\n            num_workers=2)\n    \n    ","metadata":{"execution":{"iopub.status.busy":"2022-05-16T05:20:23.012989Z","iopub.execute_input":"2022-05-16T05:20:23.013488Z","iopub.status.idle":"2022-05-16T05:20:23.025817Z","shell.execute_reply.started":"2022-05-16T05:20:23.013446Z","shell.execute_reply":"2022-05-16T05:20:23.025108Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"MODEL_NAME = \"t5-base\"\n\ntokenizer = T5Tokenizer.from_pretrained(MODEL_NAME)","metadata":{"execution":{"iopub.status.busy":"2022-05-16T05:20:23.027406Z","iopub.execute_input":"2022-05-16T05:20:23.027980Z","iopub.status.idle":"2022-05-16T05:20:35.640069Z","shell.execute_reply.started":"2022-05-16T05:20:23.027925Z","shell.execute_reply":"2022-05-16T05:20:35.639273Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"text_token_counts, summary_token_counts = [],[]\nfor _, row in train_df.iterrows():\n    text_token_count=len(tokenizer.encode(row['text']))\n    text_token_counts.append(text_token_count)\n    \n    summary_token_count=len(tokenizer.encode(row['summary']))\n    summary_token_counts.append(summary_token_count)","metadata":{"execution":{"iopub.status.busy":"2022-05-16T05:20:35.643587Z","iopub.execute_input":"2022-05-16T05:20:35.644984Z","iopub.status.idle":"2022-05-16T05:20:45.144179Z","shell.execute_reply.started":"2022-05-16T05:20:35.644940Z","shell.execute_reply":"2022-05-16T05:20:45.143452Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"fig, (ax1,ax2) = plt.subplots(1,2)\n\nsns.histplot(text_token_counts,ax=ax1)\nax1.set_title(\"Full text token counts\")\n\nsns.histplot(summary_token_counts,ax=ax2)\nax2.set_title(\"Summary token counts\")\n\nfig.show()\n","metadata":{"execution":{"iopub.status.busy":"2022-05-16T05:20:45.145666Z","iopub.execute_input":"2022-05-16T05:20:45.145931Z","iopub.status.idle":"2022-05-16T05:20:46.319513Z","shell.execute_reply.started":"2022-05-16T05:20:45.145896Z","shell.execute_reply":"2022-05-16T05:20:46.318688Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"N_EPOCHS = 1\nBATCH_SIZE = 8\n\ndata_module = NewsSummaryDataModule(train_df,test_df,tokenizer,batch_size=BATCH_SIZE)\n","metadata":{"execution":{"iopub.status.busy":"2022-05-16T05:20:46.321019Z","iopub.execute_input":"2022-05-16T05:20:46.321286Z","iopub.status.idle":"2022-05-16T05:20:46.328204Z","shell.execute_reply.started":"2022-05-16T05:20:46.321249Z","shell.execute_reply":"2022-05-16T05:20:46.327371Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"class NewsSummaryModel(pl.LightningModule):\n    def __init__(self):\n        super().__init__()\n        self.model = T5ForConditionalGeneration.from_pretrained(MODEL_NAME, return_dict=True)\n        \n    def forward(self, inputs_ids, attention_mask, decoder_attention_mask, labels=None):\n        output = self.model(inputs_ids,\n                            attention_mask=attention_mask,\n                            labels=labels,\n                            decoder_attention_mask=decoder_attention_mask)\n        return output.loss, output.logits\n    \n    def step(self, batch, batch_idx):\n        input_ids=batch[\"text_input_ids\"]\n        attention_mask = batch[\"text_attention_mask\"]\n        labels=batch[\"labels\"]\n        labels_attention_mask = batch[\"labels_attention_mask\"]\n        \n        loss, outputs = self.forward(inputs_ids=input_ids,\n                             attention_mask=attention_mask,\n                             decoder_attention_mask=labels_attention_mask,\n                             labels=labels)\n        return loss, outputs\n    \n    def training_step(self, batch, batch_idx):\n        loss, outputs = self.step(batch, batch_idx)\n        \n        self.log(\"train_loss\",loss, prog_bar=True, logger=True)\n        return loss\n    \n    def validation_step(self, batch, batch_idx):\n        loss, outputs = self.step(batch, batch_idx)\n        self.log(\"val_loss\",loss, prog_bar=True, logger=True)\n        return loss\n    \n    def test_step(self, batch, batch_idx):\n        loss, outputs = self.step(batch, batch_idx)\n        self.log(\"test_loss\",loss, prog_bar=True, logger=True)\n        return loss\n    \n    def configure_optimizers(self):\n        return AdamW(self.parameters(), lr=0.0001)\n    ","metadata":{"execution":{"iopub.status.busy":"2022-05-16T05:20:46.329495Z","iopub.execute_input":"2022-05-16T05:20:46.329700Z","iopub.status.idle":"2022-05-16T05:20:46.344455Z","shell.execute_reply.started":"2022-05-16T05:20:46.329674Z","shell.execute_reply":"2022-05-16T05:20:46.343653Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"model = NewsSummaryModel()","metadata":{"execution":{"iopub.status.busy":"2022-05-16T05:20:46.345832Z","iopub.execute_input":"2022-05-16T05:20:46.346110Z","iopub.status.idle":"2022-05-16T05:22:13.088457Z","shell.execute_reply.started":"2022-05-16T05:20:46.346074Z","shell.execute_reply":"2022-05-16T05:22:13.087642Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"!kill 2079\n%load_ext tensorboard\n%tensorboard --logdir ./lightning_logs","metadata":{"execution":{"iopub.status.busy":"2022-05-16T05:22:13.089760Z","iopub.execute_input":"2022-05-16T05:22:13.090446Z","iopub.status.idle":"2022-05-16T05:22:18.422090Z","shell.execute_reply.started":"2022-05-16T05:22:13.090404Z","shell.execute_reply":"2022-05-16T05:22:18.421230Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"checkpoint_callback = ModelCheckpoint(\n                        dirpath=\"checkpoints\",\n                        filename=\"best-checkpoint\",\n                        save_top_k=1,\n                        verbose=True, \n                        monitor=\"val_loss\",\n                        mode=\"min\")\nlogger = TensorBoardLogger(\"lightning_logs\", name=\"news-summary\")\n\nfrom pytorch_lightning.callbacks.progress import ProgressBar\nclass LitProgressBar(ProgressBar):\n\n    def init_validation_tqdm(self):\n        bar = super().init_validation_tqdm()\n        bar.set_description('running validation ...')\n        bar.refresh_rate=30\n        return bar\n\nbar = LitProgressBar()\n\ntrainer = pl.Trainer(logger=logger,\n                    enable_checkpointing=checkpoint_callback,\n                    max_epochs=N_EPOCHS,\n                    gpus=1,\n                    progress_bar_refresh_rate=30)","metadata":{"execution":{"iopub.status.busy":"2022-05-16T05:22:18.423989Z","iopub.execute_input":"2022-05-16T05:22:18.424541Z","iopub.status.idle":"2022-05-16T05:22:18.480572Z","shell.execute_reply.started":"2022-05-16T05:22:18.424480Z","shell.execute_reply":"2022-05-16T05:22:18.479874Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"import torch\ntorch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2022-05-16T05:22:18.482034Z","iopub.execute_input":"2022-05-16T05:22:18.482508Z","iopub.status.idle":"2022-05-16T05:22:18.487080Z","shell.execute_reply.started":"2022-05-16T05:22:18.482470Z","shell.execute_reply":"2022-05-16T05:22:18.485665Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"trainer.fit(model,data_module)","metadata":{"execution":{"iopub.status.busy":"2022-05-16T05:22:18.488702Z","iopub.execute_input":"2022-05-16T05:22:18.489298Z","iopub.status.idle":"2022-05-16T05:28:36.498649Z","shell.execute_reply.started":"2022-05-16T05:22:18.489257Z","shell.execute_reply":"2022-05-16T05:28:36.497876Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"trained_model = NewsSummaryModel.load_from_checkpoint(\n    trainer.checkpoint_callback.best_model_path\n    )","metadata":{"execution":{"iopub.status.busy":"2022-05-16T05:28:36.503655Z","iopub.execute_input":"2022-05-16T05:28:36.505729Z","iopub.status.idle":"2022-05-16T05:28:47.626030Z","shell.execute_reply.started":"2022-05-16T05:28:36.505685Z","shell.execute_reply":"2022-05-16T05:28:47.625176Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"def summarize(text):\n    text_encoding = tokenizer(\n        text,\n        max_length=512,\n        padding=\"max_length\",\n        truncation=True,\n        return_attention_mask=True,\n        add_special_tokens=True,\n        return_tensors='pt'\n        )\n    generated_ids = trained_model.model.generate(\n        input_ids=text_encoding[\"input_ids\"],\n        attention_mask=text_encoding[\"attention_mask\"],\n        max_length=150,\n        num_beams=2,\n        repetition_penalty=2.5,\n        length_penalty=1.0,\n        early_stopping=True)\n    preds = [\n        tokenizer.decode(gen_id, skip_special_tokens=True, clean_up_tokenization_spaces=True) for gen_id in generated_ids\n    ]\n    return \"\".join(preds)\n    ","metadata":{"execution":{"iopub.status.busy":"2022-05-16T05:28:47.627913Z","iopub.execute_input":"2022-05-16T05:28:47.628178Z","iopub.status.idle":"2022-05-16T05:28:47.636888Z","shell.execute_reply.started":"2022-05-16T05:28:47.628142Z","shell.execute_reply":"2022-05-16T05:28:47.636078Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"sample_row = test_df.iloc[69]\ntext = sample_row[\"text\"]\nref_summary = sample_row[\"summary\"]\n\nmodel_summary = summarize(text)\n\nprint('Original text :  \\n', text)\nprint('\\nPredicted summary :  \\n', model_summary)\nprint('\\nOriginal summary :  \\n', ref_summary)","metadata":{"execution":{"iopub.status.busy":"2022-05-16T05:28:47.638015Z","iopub.execute_input":"2022-05-16T05:28:47.638671Z","iopub.status.idle":"2022-05-16T05:28:56.452357Z","shell.execute_reply.started":"2022-05-16T05:28:47.638629Z","shell.execute_reply":"2022-05-16T05:28:56.450828Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"text = \"The architecture of MSU-Net is illustrated in Figure 1. MSU-Net has a contraction path and an expansion path. The network architecture follows encoder-decoder. In original U-Net, each block consists of two convolutional layers. However, there is still a drawback in this block. Due to the limitation of the receptive field, the network does not achieve better performance in feature extraction and feature restoration. The convolution blocks in encoder of the original U-Net are replaced with multi-scale blocks to obtain MSU-Net (encoder). The convolution blocks in decoder of the original U-Net are replaced with multi-scale blocks to obtain MSU-Net (decoder). The experimental results are illustrated in Table 2. In MSU-Net, the multi-scale block (37) is used to replace the all convolution block in the original U-Net. Multi-scale block enables encoder to extract more detailed information. Multi-scale block makes the features of decoder restoration more complete.\"\nmodel_summary = summarize(text)\nprint('\\nPredicted summary :  \\n', model_summary)","metadata":{"execution":{"iopub.status.busy":"2022-05-16T05:28:56.453615Z","iopub.execute_input":"2022-05-16T05:28:56.454470Z","iopub.status.idle":"2022-05-16T05:29:05.338968Z","shell.execute_reply.started":"2022-05-16T05:28:56.454427Z","shell.execute_reply":"2022-05-16T05:29:05.337140Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}